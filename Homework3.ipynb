{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 433)\n",
      "(506691, 432)\n"
     ]
    }
   ],
   "source": [
    "train_transaction = pd.read_csv('train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "train_identity = pd.read_csv('train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col='TransactionID')\n",
    "\n",
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "y_train = train['isFraud'].copy()\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "# Drop target, fill in NaNs\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "X_train = X_train.fillna(-999)\n",
    "X_test = X_test.fillna(-999)\n",
    "\n",
    "# Label Encoding\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "        X_test[f] = lbl.transform(list(X_test[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    569877\n",
      "Fraud         20663\n",
      "Name: isFraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_transaction = pd.read_csv('train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "train_identity = pd.read_csv('train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(train.isFraud.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20663\n",
      "569877\n"
     ]
    }
   ],
   "source": [
    "non_fraud = train_transaction.loc[train['isFraud'] == 0]\n",
    "fraud = train_transaction.loc[train['isFraud'] == 1]\n",
    "\n",
    "print(len(fraud))\n",
    "print(len(non_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 403.2x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.catplot(x=\"isFraud\", col=\"isFraud\", data=train_transaction, kind=\"count\", height=4, aspect=.7);\n",
    "import seaborn as sns\n",
    "#sns.countplot(x='isFraud',data=train_transaction)\n",
    "\n",
    "sns.catplot(x=\"isFraud\", col=\"isFraud\", data=train_transaction, kind=\"count\", height=4, aspect=.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state=0, C=1e5, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9650066041250381"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['isFraud'] = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('logistic_regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework3.ipynb         \u001b[31msandbox.ipynb\u001b[m\u001b[m           \u001b[31mtrain_identity.csv\u001b[m\u001b[m\r\n",
      "logistic_regression.csv \u001b[31mtest_identity.csv\u001b[m\u001b[m       \u001b[31mtrain_transaction.csv\u001b[m\u001b[m\r\n",
      "\u001b[31msample_submission.csv\u001b[m\u001b[m   \u001b[31mtest_transaction.csv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.135731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.151380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.153893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.134131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.117876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3663554</td>\n",
       "      <td>0.125276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3663555</td>\n",
       "      <td>0.117031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3663556</td>\n",
       "      <td>0.122380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3663557</td>\n",
       "      <td>0.154694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3663558</td>\n",
       "      <td>0.107060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3663559</td>\n",
       "      <td>0.115258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3663560</td>\n",
       "      <td>0.135993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3663561</td>\n",
       "      <td>0.115138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3663562</td>\n",
       "      <td>0.117316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3663563</td>\n",
       "      <td>0.125757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3663564</td>\n",
       "      <td>0.134554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3663565</td>\n",
       "      <td>0.101124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3663566</td>\n",
       "      <td>0.130303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3663567</td>\n",
       "      <td>0.115818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3663568</td>\n",
       "      <td>0.130268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3663569</td>\n",
       "      <td>0.102209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3663570</td>\n",
       "      <td>0.108096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3663571</td>\n",
       "      <td>0.100796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3663572</td>\n",
       "      <td>0.127847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3663573</td>\n",
       "      <td>0.128123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3663574</td>\n",
       "      <td>0.119926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3663575</td>\n",
       "      <td>0.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3663576</td>\n",
       "      <td>0.131154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3663577</td>\n",
       "      <td>0.127647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3663578</td>\n",
       "      <td>0.122880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506661</th>\n",
       "      <td>4170210</td>\n",
       "      <td>0.108415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506662</th>\n",
       "      <td>4170211</td>\n",
       "      <td>0.144765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506663</th>\n",
       "      <td>4170212</td>\n",
       "      <td>0.102530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506664</th>\n",
       "      <td>4170213</td>\n",
       "      <td>0.149383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506665</th>\n",
       "      <td>4170214</td>\n",
       "      <td>0.262725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506666</th>\n",
       "      <td>4170215</td>\n",
       "      <td>0.144113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506667</th>\n",
       "      <td>4170216</td>\n",
       "      <td>0.138193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506668</th>\n",
       "      <td>4170217</td>\n",
       "      <td>0.117244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506669</th>\n",
       "      <td>4170218</td>\n",
       "      <td>0.153143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506670</th>\n",
       "      <td>4170219</td>\n",
       "      <td>0.337380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506671</th>\n",
       "      <td>4170220</td>\n",
       "      <td>0.113438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506672</th>\n",
       "      <td>4170221</td>\n",
       "      <td>0.149380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506673</th>\n",
       "      <td>4170222</td>\n",
       "      <td>0.144735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506674</th>\n",
       "      <td>4170223</td>\n",
       "      <td>0.224613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506675</th>\n",
       "      <td>4170224</td>\n",
       "      <td>0.304157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506676</th>\n",
       "      <td>4170225</td>\n",
       "      <td>0.225368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506677</th>\n",
       "      <td>4170226</td>\n",
       "      <td>0.282101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506678</th>\n",
       "      <td>4170227</td>\n",
       "      <td>0.133621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506679</th>\n",
       "      <td>4170228</td>\n",
       "      <td>0.289777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506680</th>\n",
       "      <td>4170229</td>\n",
       "      <td>0.306480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506681</th>\n",
       "      <td>4170230</td>\n",
       "      <td>0.257187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506682</th>\n",
       "      <td>4170231</td>\n",
       "      <td>0.138087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506683</th>\n",
       "      <td>4170232</td>\n",
       "      <td>0.125628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506684</th>\n",
       "      <td>4170233</td>\n",
       "      <td>0.225419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506685</th>\n",
       "      <td>4170234</td>\n",
       "      <td>0.274151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506686</th>\n",
       "      <td>4170235</td>\n",
       "      <td>0.109891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506687</th>\n",
       "      <td>4170236</td>\n",
       "      <td>0.313260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506688</th>\n",
       "      <td>4170237</td>\n",
       "      <td>0.112863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506689</th>\n",
       "      <td>4170238</td>\n",
       "      <td>0.113103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506690</th>\n",
       "      <td>4170239</td>\n",
       "      <td>0.265544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506691 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID   isFraud\n",
       "0             3663549  0.135731\n",
       "1             3663550  0.151380\n",
       "2             3663551  0.153893\n",
       "3             3663552  0.134131\n",
       "4             3663553  0.117876\n",
       "5             3663554  0.125276\n",
       "6             3663555  0.117031\n",
       "7             3663556  0.122380\n",
       "8             3663557  0.154694\n",
       "9             3663558  0.107060\n",
       "10            3663559  0.115258\n",
       "11            3663560  0.135993\n",
       "12            3663561  0.115138\n",
       "13            3663562  0.117316\n",
       "14            3663563  0.125757\n",
       "15            3663564  0.134554\n",
       "16            3663565  0.101124\n",
       "17            3663566  0.130303\n",
       "18            3663567  0.115818\n",
       "19            3663568  0.130268\n",
       "20            3663569  0.102209\n",
       "21            3663570  0.108096\n",
       "22            3663571  0.100796\n",
       "23            3663572  0.127847\n",
       "24            3663573  0.128123\n",
       "25            3663574  0.119926\n",
       "26            3663575  0.108900\n",
       "27            3663576  0.131154\n",
       "28            3663577  0.127647\n",
       "29            3663578  0.122880\n",
       "...               ...       ...\n",
       "506661        4170210  0.108415\n",
       "506662        4170211  0.144765\n",
       "506663        4170212  0.102530\n",
       "506664        4170213  0.149383\n",
       "506665        4170214  0.262725\n",
       "506666        4170215  0.144113\n",
       "506667        4170216  0.138193\n",
       "506668        4170217  0.117244\n",
       "506669        4170218  0.153143\n",
       "506670        4170219  0.337380\n",
       "506671        4170220  0.113438\n",
       "506672        4170221  0.149380\n",
       "506673        4170222  0.144735\n",
       "506674        4170223  0.224613\n",
       "506675        4170224  0.304157\n",
       "506676        4170225  0.225368\n",
       "506677        4170226  0.282101\n",
       "506678        4170227  0.133621\n",
       "506679        4170228  0.289777\n",
       "506680        4170229  0.306480\n",
       "506681        4170230  0.257187\n",
       "506682        4170231  0.138087\n",
       "506683        4170232  0.125628\n",
       "506684        4170233  0.225419\n",
       "506685        4170234  0.274151\n",
       "506686        4170235  0.109891\n",
       "506687        4170236  0.313260\n",
       "506688        4170237  0.112863\n",
       "506689        4170238  0.113103\n",
       "506690        4170239  0.265544\n",
       "\n",
       "[506691 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('logistic_regression.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
